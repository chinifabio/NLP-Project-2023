{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\andre\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\andre\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spacy in c:\\users\\andre\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (3.5.3)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\users\\andre\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from spacy) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\andre\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from spacy) (1.0.4)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\andre\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from spacy) (1.0.9)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\andre\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from spacy) (2.0.7)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\andre\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from spacy) (3.0.8)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in c:\\users\\andre\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from spacy) (8.1.10)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\users\\andre\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from spacy) (1.1.1)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\andre\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from spacy) (2.4.6)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\andre\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from spacy) (2.0.8)\n",
      "Requirement already satisfied: typer<0.8.0,>=0.3.0 in c:\\users\\andre\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from spacy) (0.7.0)\n",
      "Requirement already satisfied: pathy>=0.10.0 in c:\\users\\andre\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from spacy) (0.10.1)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in c:\\users\\andre\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from spacy) (6.3.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\andre\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from spacy) (4.65.0)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\users\\andre\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from spacy) (1.24.2)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\andre\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from spacy) (2.28.2)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in c:\\users\\andre\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from spacy) (1.10.7)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\andre\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from spacy) (3.1.2)\n",
      "Requirement already satisfied: setuptools in c:\\users\\andre\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from spacy) (49.2.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\andre\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from spacy) (23.0)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\andre\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from spacy) (3.3.0)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in c:\\users\\andre\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy) (4.5.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\andre\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\andre\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\andre\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\andre\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2022.12.7)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in c:\\users\\andre\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from thinc<8.2.0,>=8.1.8->spacy) (0.7.9)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\andre\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from thinc<8.2.0,>=8.1.8->spacy) (0.0.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\andre\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy) (0.4.6)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\andre\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from typer<0.8.0,>=0.3.0->spacy) (8.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\andre\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from jinja2->spacy) (2.1.2)\n",
      "Collecting en-core-web-sm==3.5.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.5.0/en_core_web_sm-3.5.0-py3-none-any.whl (12.8 MB)\n",
      "                                              0.0/12.8 MB ? eta -:--:--\n",
      "     -                                        0.5/12.8 MB 10.0 MB/s eta 0:00:02\n",
      "     ---                                      1.2/12.8 MB 12.5 MB/s eta 0:00:01\n",
      "     ------                                   2.1/12.8 MB 14.7 MB/s eta 0:00:01\n",
      "     ---------                                3.0/12.8 MB 16.0 MB/s eta 0:00:01\n",
      "     -------------                            4.2/12.8 MB 17.7 MB/s eta 0:00:01\n",
      "     ----------------                         5.4/12.8 MB 19.0 MB/s eta 0:00:01\n",
      "     --------------------                     6.6/12.8 MB 19.9 MB/s eta 0:00:01\n",
      "     ------------------------                 7.8/12.8 MB 20.9 MB/s eta 0:00:01\n",
      "     ----------------------------             9.1/12.8 MB 22.2 MB/s eta 0:00:01\n",
      "     -------------------------------         10.2/12.8 MB 22.5 MB/s eta 0:00:01\n",
      "     -----------------------------------     11.5/12.8 MB 24.2 MB/s eta 0:00:01\n",
      "     --------------------------------------  12.8/12.8 MB 26.2 MB/s eta 0:00:01\n",
      "     --------------------------------------  12.8/12.8 MB 26.2 MB/s eta 0:00:01\n",
      "     --------------------------------------- 12.8/12.8 MB 19.9 MB/s eta 0:00:00\n",
      "Requirement already satisfied: spacy<3.6.0,>=3.5.0 in c:\\users\\andre\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from en-core-web-sm==3.5.0) (3.5.3)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\users\\andre\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\andre\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.0.4)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\andre\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.0.9)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\andre\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.0.7)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\andre\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.0.8)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in c:\\users\\andre\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (8.1.10)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\users\\andre\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.1.1)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\andre\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.4.6)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\andre\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.0.8)\n",
      "Requirement already satisfied: typer<0.8.0,>=0.3.0 in c:\\users\\andre\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.7.0)\n",
      "Requirement already satisfied: pathy>=0.10.0 in c:\\users\\andre\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.10.1)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in c:\\users\\andre\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (6.3.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\andre\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (4.65.0)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\users\\andre\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.24.2)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\andre\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.28.2)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in c:\\users\\andre\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.10.7)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\andre\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.1.2)\n",
      "Requirement already satisfied: setuptools in c:\\users\\andre\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (49.2.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\andre\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (23.0)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\andre\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.3.0)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in c:\\users\\andre\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (4.5.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\andre\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\andre\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\andre\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\andre\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2022.12.7)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in c:\\users\\andre\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.7.9)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\andre\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.0.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\andre\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.4.6)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\andre\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from typer<0.8.0,>=0.3.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (8.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\andre\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from jinja2->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.1.2)\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import arccos\n",
    "import nltk\n",
    "nltk.download(\"punkt\")\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from string import punctuation\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "from unidecode import unidecode\n",
    "!pip install -U spacy\n",
    "import spacy\n",
    "import sys\n",
    "!{sys.executable} -m spacy download en_core_web_sm\n",
    "spacy_nlp = spacy.load('en_core_web_sm', disable=['parser', 'ner'])\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of the Dataframe (5749, 7)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>genre</th>\n",
       "      <th>filename</th>\n",
       "      <th>year</th>\n",
       "      <th>index</th>\n",
       "      <th>score</th>\n",
       "      <th>sentence1</th>\n",
       "      <th>sentence2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>main-captions</td>\n",
       "      <td>MSRvid</td>\n",
       "      <td>2012test</td>\n",
       "      <td>1</td>\n",
       "      <td>5.00</td>\n",
       "      <td>A plane is taking off.</td>\n",
       "      <td>An air plane is taking off.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>main-captions</td>\n",
       "      <td>MSRvid</td>\n",
       "      <td>2012test</td>\n",
       "      <td>4</td>\n",
       "      <td>3.80</td>\n",
       "      <td>A man is playing a large flute.</td>\n",
       "      <td>A man is playing a flute.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>main-captions</td>\n",
       "      <td>MSRvid</td>\n",
       "      <td>2012test</td>\n",
       "      <td>5</td>\n",
       "      <td>3.80</td>\n",
       "      <td>A man is spreading shreded cheese on a pizza.</td>\n",
       "      <td>A man is spreading shredded cheese on an uncoo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>main-captions</td>\n",
       "      <td>MSRvid</td>\n",
       "      <td>2012test</td>\n",
       "      <td>6</td>\n",
       "      <td>2.60</td>\n",
       "      <td>Three men are playing chess.</td>\n",
       "      <td>Two men are playing chess.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>main-captions</td>\n",
       "      <td>MSRvid</td>\n",
       "      <td>2012test</td>\n",
       "      <td>9</td>\n",
       "      <td>4.25</td>\n",
       "      <td>A man is playing the cello.</td>\n",
       "      <td>A man seated is playing the cello.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>main-captions</td>\n",
       "      <td>MSRvid</td>\n",
       "      <td>2012test</td>\n",
       "      <td>11</td>\n",
       "      <td>4.25</td>\n",
       "      <td>Some men are fighting.</td>\n",
       "      <td>Two men are fighting.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>main-captions</td>\n",
       "      <td>MSRvid</td>\n",
       "      <td>2012test</td>\n",
       "      <td>12</td>\n",
       "      <td>0.50</td>\n",
       "      <td>A man is smoking.</td>\n",
       "      <td>A man is skating.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>main-captions</td>\n",
       "      <td>MSRvid</td>\n",
       "      <td>2012test</td>\n",
       "      <td>13</td>\n",
       "      <td>1.60</td>\n",
       "      <td>The man is playing the piano.</td>\n",
       "      <td>The man is playing the guitar.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>main-captions</td>\n",
       "      <td>MSRvid</td>\n",
       "      <td>2012test</td>\n",
       "      <td>14</td>\n",
       "      <td>2.20</td>\n",
       "      <td>A man is playing on a guitar and singing.</td>\n",
       "      <td>A woman is playing an acoustic guitar and sing...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>main-captions</td>\n",
       "      <td>MSRvid</td>\n",
       "      <td>2012test</td>\n",
       "      <td>16</td>\n",
       "      <td>5.00</td>\n",
       "      <td>A person is throwing a cat on to the ceiling.</td>\n",
       "      <td>A person throws a cat on the ceiling.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           genre filename      year  index  score   \n",
       "0  main-captions   MSRvid  2012test      1   5.00  \\\n",
       "1  main-captions   MSRvid  2012test      4   3.80   \n",
       "2  main-captions   MSRvid  2012test      5   3.80   \n",
       "3  main-captions   MSRvid  2012test      6   2.60   \n",
       "4  main-captions   MSRvid  2012test      9   4.25   \n",
       "5  main-captions   MSRvid  2012test     11   4.25   \n",
       "6  main-captions   MSRvid  2012test     12   0.50   \n",
       "7  main-captions   MSRvid  2012test     13   1.60   \n",
       "8  main-captions   MSRvid  2012test     14   2.20   \n",
       "9  main-captions   MSRvid  2012test     16   5.00   \n",
       "\n",
       "                                       sentence1   \n",
       "0                         A plane is taking off.  \\\n",
       "1                A man is playing a large flute.   \n",
       "2  A man is spreading shreded cheese on a pizza.   \n",
       "3                   Three men are playing chess.   \n",
       "4                    A man is playing the cello.   \n",
       "5                         Some men are fighting.   \n",
       "6                              A man is smoking.   \n",
       "7                  The man is playing the piano.   \n",
       "8      A man is playing on a guitar and singing.   \n",
       "9  A person is throwing a cat on to the ceiling.   \n",
       "\n",
       "                                           sentence2  \n",
       "0                        An air plane is taking off.  \n",
       "1                          A man is playing a flute.  \n",
       "2  A man is spreading shredded cheese on an uncoo...  \n",
       "3                         Two men are playing chess.  \n",
       "4                 A man seated is playing the cello.  \n",
       "5                              Two men are fighting.  \n",
       "6                                  A man is skating.  \n",
       "7                     The man is playing the guitar.  \n",
       "8  A woman is playing an acoustic guitar and sing...  \n",
       "9              A person throws a cat on the ceiling.  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def on_bad_line(values):\n",
    "    return values[:7]\n",
    "\n",
    "columns_mapping = {\n",
    "    0: 'genre',\n",
    "    1: 'filename',\n",
    "    2: 'year',\n",
    "    3: 'index',\n",
    "    4: 'score',\n",
    "    5: 'sentence1',\n",
    "    6: 'sentence2'\n",
    "}\n",
    "\n",
    "# quotings 3 = csv.QUOTE_NONE\n",
    "train_df = pd.read_csv('Dataset/sts-train.csv', sep=\"\\t\", on_bad_lines=on_bad_line, engine='python', header=None, encoding='utf-8', quoting=3).rename(columns=columns_mapping)\n",
    "print(f'shape of the Dataframe {train_df.shape}')\n",
    "train_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of the Dataframe (1500, 7)\n",
      "shape of the Dataframe (1379, 7)\n"
     ]
    }
   ],
   "source": [
    "dev_df = pd.read_csv('Dataset/sts-dev.csv', sep=\"\\t\", on_bad_lines=on_bad_line, engine='python', header=None, encoding='utf-8', quoting=3).rename(columns=columns_mapping)\n",
    "print(f'shape of the Dataframe {dev_df.shape}')\n",
    "\n",
    "test_df = pd.read_csv('Dataset/sts-test.csv', sep=\"\\t\", on_bad_lines=on_bad_line, engine='python', header=None, encoding='utf-8', quoting=3).rename(columns=columns_mapping)\n",
    "print(f'shape of the Dataframe {test_df.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of sentences: 10566\n"
     ]
    }
   ],
   "source": [
    "sentences1 = train_df[\"sentence1\"]\n",
    "sentences2 = train_df[\"sentence2\"]\n",
    "sentences_list = np.unique(np.concatenate((np.ravel(sentences1.values),np.ravel(sentences2.values))))\n",
    "\n",
    "print(f\"Total number of sentences: {len(sentences_list)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' - Income, top rate:  percent.' ' Foxe was mostly frozen.'\n",
      " \" billion . Everyone in the world at Mexico's current prosperity level.\"\n",
      " ' warmed.C from the year prior.'\n",
      " '\"Americans don\\'t cut and run, we have to see this misadventure through,\" she said.']\n",
      "['income top rate percent' 'foxe mostly frozen'\n",
      " 'billion everyone world mexicos current prosperity level'\n",
      " 'warmedc year prior' 'americans dont cut run see misadventure said']\n",
      "['income top rate percent' 'foxe mostly frozen'\n",
      " 'billion everyone world mexicos current prosperity level'\n",
      " 'warmedc year prior' 'americans cut run see misadventure say']\n"
     ]
    }
   ],
   "source": [
    "def remove_special_chars(text):\n",
    "    regex = '[' + punctuation + ']'\n",
    "    return re.sub(regex,'',unidecode(text)).lower()\n",
    "\n",
    "def remove_stop_words(text):\n",
    "    stop_words = stopwords.words('english')\n",
    "    return ' '.join([word for word in text.split() if word not in stop_words])\n",
    "\n",
    "def lemmatize(text):\n",
    "    parsed_sentence = spacy_nlp(str(text))\n",
    "    lemmatized_sentence = ' '.join([word.lemma_ for word in parsed_sentence])\n",
    "    return lemmatized_sentence\n",
    "\n",
    "def substitute_number(sentence):\n",
    "    return re.sub(r'\\d+', ' number ', sentence)\n",
    "\n",
    "#TODO mostrare differenze tra originale e lemmatizzazione\n",
    "\n",
    "\n",
    "no_punct_sentences_list = np.array([remove_special_chars(string) for string in sentences_list])\n",
    "clean_sentences_list = np.array([remove_stop_words(string) for string in no_punct_sentences_list])\n",
    "lemmatized_sentences_list = np.array([remove_stop_words(lemmatize(remove_special_chars(sentence)).lower()) for sentence in clean_sentences_list])\n",
    "\n",
    "\n",
    "\n",
    "print(sentences_list[:5])\n",
    "print(clean_sentences_list[:5])\n",
    "print(lemmatized_sentences_list[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean length of sentences in characters: 59.37\n"
     ]
    }
   ],
   "source": [
    "array_len = np.vectorize(len)(sentences_list)\n",
    "mean_len = np.mean(array_len)\n",
    "print(f\"Mean length of sentences in characters: {mean_len:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_dataset = pd.DataFrame({\n",
    "    'sentence1': train_df['sentence1'].map(remove_special_chars).map(remove_stop_words),\n",
    "    'sentence2': train_df['sentence2'].map(remove_special_chars).map(remove_stop_words),\n",
    "    'score': train_df['score'] / 5\n",
    "})\n",
    "\n",
    "clean_test_dataset = pd.DataFrame({\n",
    "    'sentence1': test_df['sentence1'].map(remove_special_chars).map(remove_stop_words),\n",
    "    'sentence2': test_df['sentence2'].map(remove_special_chars).map(remove_stop_words),\n",
    "    'score': test_df['score'] / 5\n",
    "})\n",
    "\n",
    "no_number_dataset = pd.DataFrame({\n",
    "    'sentence1': clean_dataset['sentence1'].map(substitute_number),\n",
    "    'sentence2': clean_dataset['sentence2'].map(substitute_number),\n",
    "    'score': clean_dataset['score']\n",
    "})\n",
    "\n",
    "lemmatized_dataset = pd.DataFrame({\n",
    "    'sentence1': clean_dataset['sentence1'].map(lemmatize),\n",
    "    'sentence2': clean_dataset['sentence2'].map(lemmatize),\n",
    "    'score': clean_dataset['score']\n",
    "})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformers\n",
    "![Comparison bi-encoder and cross-encoder](https://raw.githubusercontent.com/UKPLab/sentence-transformers/master/docs/img/Bi_vs_Cross-Encoder.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bi-Encoders\n",
    "Bi-Encoders produce for a given sentence a sentence embedding. We pass to a BERT independently the sentences A and B, which result in the sentence embeddings u and v. These sentence embedding can then be compared using cosine similarity\n",
    "\n",
    "In this example we fine tune a pre-trained SentenceTransformer model on the STS benchmark dataset.\n",
    "\n",
    "Reimers, N., & Gurevych, I. (2019). Sentence-BERT: Sentence embeddings using Siamese BERT-networks. In arXiv [cs.CL]. http://arxiv.org/abs/1908.10084"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine Tuning a pre-trained model\n",
    "In this example we fine tune a pre-trained model. The model was first trained on NLI data, we now finetune it on the STS benchmark dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import math\n",
    "from sentence_transformers import SentenceTransformer, LoggingHandler, losses, util, InputExample\n",
    "from sentence_transformers.evaluation import EmbeddingSimilarityEvaluator\n",
    "import logging\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-05-27 10:46:45 - Load pretrained SentenceTransformer: nli-distilroberta-base-v2\n",
      "2023-05-27 10:46:46 - Use pytorch device: cpu\n"
     ]
    }
   ],
   "source": [
    "#### Just some code to print debug information to stdout\n",
    "logging.basicConfig(format='%(asctime)s - %(message)s',\n",
    "                    datefmt='%Y-%m-%d %H:%M:%S',\n",
    "                    level=logging.INFO,\n",
    "                    handlers=[LoggingHandler()])\n",
    "\n",
    "# Read the dataset\n",
    "model_name = 'nli-distilroberta-base-v2'\n",
    "train_batch_size = 16\n",
    "num_epochs = 10\n",
    "model_save_path = 'output/bi_encoder_fine_tuning-'+model_name+'-'+datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "\n",
    "# Load a pre-trained sentence transformer model\n",
    "model = SentenceTransformer(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-05-27 10:46:57 - Read STSbenchmark train dataset\n"
     ]
    }
   ],
   "source": [
    "# Convert the dataset to a DataLoader ready for training\n",
    "logging.info(\"Read STSbenchmark train dataset\")\n",
    "\n",
    "train_samples = []\n",
    "dev_samples = []\n",
    "test_samples = []\n",
    "\n",
    "# Loading datasets from csv files\n",
    "for idx, row in train_df.iterrows():\n",
    "\n",
    "    score = float(row['score']) / 5.0  # Normalize score to range 0 ... 1\n",
    "\n",
    "    #As we want to get symmetric scores, i.e. CrossEncoder(A,B) = CrossEncoder(B,A), we pass both combinations to the train set\n",
    "    train_samples.append(InputExample(texts=[row['sentence1'], row['sentence2']], label=score))\n",
    "    train_samples.append(InputExample(texts=[row['sentence2'], row['sentence1']], label=score))\n",
    "\n",
    "for idx, row in dev_df.iterrows():\n",
    "    score = float(row['score']) / 5.0  # Normalize score to range 0 ... 1\n",
    "    dev_samples.append(InputExample(texts=[row['sentence1'], row['sentence2']], label=score))\n",
    "\n",
    "for idx, row in test_df.iterrows():\n",
    "    score = float(row['score']) / 5.0  # Normalize score to range 0 ... 1\n",
    "    test_samples.append(InputExample(texts=[row['sentence1'], row['sentence2']], label=score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-05-27 10:47:04 - Read STSbenchmark dev dataset\n",
      "2023-05-27 10:47:04 - Warmup-steps: 719\n"
     ]
    }
   ],
   "source": [
    "# We wrap train_samples into a pytorch DataLoader\n",
    "train_dataloader = DataLoader(train_samples, shuffle=True, batch_size=train_batch_size)\n",
    "# We use cosine similarity as loss function.\n",
    "train_loss = losses.CosineSimilarityLoss(model=model)\n",
    "\n",
    "# Development set: Measure correlation between cosine score and gold labels\n",
    "logging.info(\"Read STSbenchmark dev dataset\")\n",
    "evaluator = EmbeddingSimilarityEvaluator.from_input_examples(dev_samples, name='sts-dev')\n",
    "\n",
    "# Configure the training\n",
    "warmup_steps = math.ceil(len(train_dataloader) * num_epochs * 0.1) #10% of train data for warm-up\n",
    "logging.info(\"Warmup-steps: {}\".format(warmup_steps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-05-27 10:42:58 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-dev dataset:\n",
      "2023-05-27 10:43:56 - Cosine-Similarity :\tPearson: 0.8580\tSpearman: 0.8638\n",
      "2023-05-27 10:43:56 - Manhattan-Distance:\tPearson: 0.8469\tSpearman: 0.8463\n",
      "2023-05-27 10:43:56 - Euclidean-Distance:\tPearson: 0.8488\tSpearman: 0.8483\n",
      "2023-05-27 10:43:56 - Dot-Product-Similarity:\tPearson: 0.8096\tSpearman: 0.8086\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8637726299065401"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Testing the model before fine-tuning\n",
    "test_evaluator = EmbeddingSimilarityEvaluator.from_input_examples(test_samples, name='sts-test')\n",
    "model.evaluate(evaluator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "model.fit(train_objectives=[(train_dataloader, train_loss)],\n",
    "          evaluator=evaluator,\n",
    "          epochs=num_epochs,\n",
    "          evaluation_steps=1000,\n",
    "          warmup_steps=warmup_steps,\n",
    "          output_path=model_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-05-27 15:14:27 - Load pretrained SentenceTransformer: training_stsbenchmark_continue_training-nli-distilroberta-base-v2-2023-05-27_12-22-39\n",
      "2023-05-27 15:14:28 - Use pytorch device: cpu\n",
      "2023-05-27 15:14:28 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-test dataset:\n",
      "2023-05-27 15:15:08 - Cosine-Similarity :\tPearson: 0.8646\tSpearman: 0.8658\n",
      "2023-05-27 15:15:08 - Manhattan-Distance:\tPearson: 0.8480\tSpearman: 0.8497\n",
      "2023-05-27 15:15:08 - Euclidean-Distance:\tPearson: 0.8501\tSpearman: 0.8517\n",
      "2023-05-27 15:15:08 - Dot-Product-Similarity:\tPearson: 0.8249\tSpearman: 0.8200\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.86583234968324"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the stored model and evaluate its performance on STS benchmark dataset\n",
    "model = SentenceTransformer(model_save_path)\n",
    "test_evaluator(model, output_path=model_save_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see fine-tuning the model on the STS benchmark dataset improves the performance."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing a pre-trained bi-encoder model already fine-tuned on STSb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'stsb-distilroberta-base-v2'\n",
    "# Load a pre-trained sentence transformer model\n",
    "pre_trained_model = SentenceTransformer(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-05-27 11:48:36 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-test dataset:\n",
      "2023-05-27 11:49:26 - Cosine-Similarity :\tPearson: 0.8634\tSpearman: 0.8641\n",
      "2023-05-27 11:49:26 - Manhattan-Distance:\tPearson: 0.8409\tSpearman: 0.8411\n",
      "2023-05-27 11:49:26 - Euclidean-Distance:\tPearson: 0.8436\tSpearman: 0.8441\n",
      "2023-05-27 11:49:26 - Dot-Product-Similarity:\tPearson: 0.8211\tSpearman: 0.8141\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8641186332195347"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_evaluator(pre_trained_model)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-Encoders\n",
    "\n",
    "With Cross-Encoders we path both sentences at once to BERT. The output is then used to predict a similarity. A Cross-Encoder does not produce a sentence embedding, they are more accurate, but also slower than Bi-Encoders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers.cross_encoder import CrossEncoder\n",
    "from sentence_transformers.cross_encoder.evaluation import CECorrelationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilroberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.dense.weight', 'roberta.pooler.dense.weight', 'roberta.pooler.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.bias']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at distilroberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-05-27 15:58:06 - Use pytorch device: cpu\n"
     ]
    }
   ],
   "source": [
    "#Define our Cross-Encoder\n",
    "train_batch_size = 16\n",
    "num_epochs = 30\n",
    "model_save_path = 'output/cross_encoder_training-'+model_name+'-'+datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "\n",
    "#We use distilroberta-base as base model and set num_labels=1, which predicts a continous score between 0 and 1\n",
    "model = CrossEncoder('distilroberta-base', num_labels=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We add an evaluator, which evaluates the performance during training\n",
    "evaluator = CECorrelationEvaluator.from_input_examples(dev_samples, name='sts-dev')\n",
    "\n",
    "\n",
    "# Configure the training\n",
    "warmup_steps = math.ceil(len(train_dataloader) * num_epochs * 0.1) #10% of train data for warm-up\n",
    "logging.info(\"Warmup-steps: {}\".format(warmup_steps))\n",
    "\n",
    "\n",
    "# Train the model\n",
    "model.fit(train_dataloader=train_dataloader,\n",
    "          evaluator=evaluator,\n",
    "          epochs=num_epochs,\n",
    "          warmup_steps=warmup_steps,\n",
    "          output_path=model_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-05-27 16:40:19 - Use pytorch device: cpu\n",
      "2023-05-27 16:40:19 - CECorrelationEvaluator: Evaluating the model on sts-test dataset:\n",
      "2023-05-27 16:41:25 - Correlation:\tPearson: 0.8533\tSpearman: 0.8439\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8438616922335536"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##### Load model and eval on test set\n",
    "model = CrossEncoder('output\\cross_encoder_training-distilroberta-base-2023-05-27_16-39-21')\n",
    "\n",
    "evaluator = CECorrelationEvaluator.from_input_examples(test_samples, name='sts-test')\n",
    "evaluator(model)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing pre-trained cross-encoder models already fine-tuned on STSb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-05-27 17:07:39 - Use pytorch device: cpu\n",
      "2023-05-27 17:07:39 - CECorrelationEvaluator: Evaluating the model on sts-test dataset:\n",
      "2023-05-27 17:09:07 - Correlation:\tPearson: 0.8851\tSpearman: 0.8792\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8791573934188543"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##### Testing stsb-distilroberta-base\n",
    "model = CrossEncoder('cross-encoder/stsb-distilroberta-base', num_labels=1)\n",
    "evaluator = CECorrelationEvaluator.from_input_examples(test_samples, name='sts-test')\n",
    "evaluator(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-05-27 16:02:31 - Use pytorch device: cpu\n",
      "2023-05-27 16:02:31 - CECorrelationEvaluator: Evaluating the model on sts-test dataset:\n",
      "2023-05-27 16:08:45 - Correlation:\tPearson: 0.9170\tSpearman: 0.9147\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.914689659080599"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##### Testing stsb-roberta-large\n",
    "model = CrossEncoder('cross-encoder/stsb-roberta-large', num_labels=1)\n",
    "\n",
    "evaluator = CECorrelationEvaluator.from_input_examples(test_samples, name='sts-test')\n",
    "evaluator(model)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see cross-encoders are more accurate, but also slower than bi-encoders. They reach state-of-the-art performance on the STS benchmark dataset."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
