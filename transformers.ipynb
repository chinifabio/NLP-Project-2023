{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "VKCGBVEonUR8"
      },
      "outputs": [],
      "source": [
        "!pip3 install -q transformers datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CZWYcZJVnX-4",
        "outputId": "283a484e-0988-44ae-88ca-b26e784a0ec9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: ktrain in /usr/local/lib/python3.10/dist-packages (0.36.0)\n",
            "Requirement already satisfied: langdetect in /usr/local/lib/python3.10/dist-packages (from ktrain) (1.0.9)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from ktrain) (1.2.2)\n",
            "Requirement already satisfied: chardet in /usr/local/lib/python3.10/dist-packages (from ktrain) (4.0.0)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from ktrain) (0.1.99)\n",
            "Requirement already satisfied: jieba in /usr/local/lib/python3.10/dist-packages (from ktrain) (0.42.1)\n",
            "Requirement already satisfied: tika in /usr/local/lib/python3.10/dist-packages (from ktrain) (2.6.0)\n",
            "Requirement already satisfied: fastprogress>=0.1.21 in /usr/local/lib/python3.10/dist-packages (from ktrain) (1.0.3)\n",
            "Requirement already satisfied: cchardet in /usr/local/lib/python3.10/dist-packages (from ktrain) (2.1.7)\n",
            "Requirement already satisfied: matplotlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from ktrain) (3.7.1)\n",
            "Requirement already satisfied: syntok>1.3.3 in /usr/local/lib/python3.10/dist-packages (from ktrain) (1.4.4)\n",
            "Requirement already satisfied: transformers>=4.17.0 in /usr/local/lib/python3.10/dist-packages (from ktrain) (4.28.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from ktrain) (2.27.1)\n",
            "Requirement already satisfied: whoosh in /usr/local/lib/python3.10/dist-packages (from ktrain) (2.7.4)\n",
            "Requirement already satisfied: keras-bert>=0.86.0 in /usr/local/lib/python3.10/dist-packages (from ktrain) (0.89.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from ktrain) (23.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from ktrain) (1.2.0)\n",
            "Requirement already satisfied: pandas>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from ktrain) (1.5.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from keras-bert>=0.86.0->ktrain) (1.22.4)\n",
            "Requirement already satisfied: keras-transformer==0.40.0 in /usr/local/lib/python3.10/dist-packages (from keras-bert>=0.86.0->ktrain) (0.40.0)\n",
            "Requirement already satisfied: keras-embed-sim==0.10.0 in /usr/local/lib/python3.10/dist-packages (from keras-transformer==0.40.0->keras-bert>=0.86.0->ktrain) (0.10.0)\n",
            "Requirement already satisfied: keras-multi-head==0.29.0 in /usr/local/lib/python3.10/dist-packages (from keras-transformer==0.40.0->keras-bert>=0.86.0->ktrain) (0.29.0)\n",
            "Requirement already satisfied: keras-layer-normalization==0.16.0 in /usr/local/lib/python3.10/dist-packages (from keras-transformer==0.40.0->keras-bert>=0.86.0->ktrain) (0.16.0)\n",
            "Requirement already satisfied: keras-position-wise-feed-forward==0.8.0 in /usr/local/lib/python3.10/dist-packages (from keras-transformer==0.40.0->keras-bert>=0.86.0->ktrain) (0.8.0)\n",
            "Requirement already satisfied: keras-pos-embd==0.13.0 in /usr/local/lib/python3.10/dist-packages (from keras-transformer==0.40.0->keras-bert>=0.86.0->ktrain) (0.13.0)\n",
            "Requirement already satisfied: keras-self-attention==0.51.0 in /usr/local/lib/python3.10/dist-packages (from keras-multi-head==0.29.0->keras-transformer==0.40.0->keras-bert>=0.86.0->ktrain) (0.51.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.0->ktrain) (2.8.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.0->ktrain) (8.4.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.0->ktrain) (4.39.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.0->ktrain) (1.0.7)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.0->ktrain) (3.0.9)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.0->ktrain) (1.4.4)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.0->ktrain) (0.11.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.1->ktrain) (2022.7.1)\n",
            "Requirement already satisfied: regex>2016 in /usr/local/lib/python3.10/dist-packages (from syntok>1.3.3->ktrain) (2022.10.31)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.17.0->ktrain) (4.65.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.17.0->ktrain) (0.13.3)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.17.0->ktrain) (6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers>=4.17.0->ktrain) (3.12.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.17.0->ktrain) (0.14.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from langdetect->ktrain) (1.16.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->ktrain) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->ktrain) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->ktrain) (3.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->ktrain) (1.26.15)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->ktrain) (1.10.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->ktrain) (3.1.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tika->ktrain) (67.7.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers>=4.17.0->ktrain) (4.5.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers>=4.17.0->ktrain) (2023.4.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install ktrain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hrAxYqQtnc46",
        "outputId": "1a9bbe9c-ac91-4e68-e51d-7ce9caa29cfd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[33mWARNING: Skipping flask as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip3 uninstall flask -y\n",
        "!pip3 install -q eli5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "311WmqpJnlB4"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "-l0Q0ad3nmxj"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "from transformers import TrainingArguments, Trainer\n",
        "from datasets import Dataset, DatasetDict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "ncO9pcienoko"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Cqk56j-ynq1L"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "if device.type != 'cuda':\n",
        "    raise SystemError('GPU device not found')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 257
        },
        "id": "munNHV5JolCY",
        "outputId": "9d1e8c70-39e8-499f-c9c4-bd55e78d1626"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "shape of the Dataframe (5749, 7)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-651c3d61-5295-407a-91e4-36cf1e0b3ab3\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>genre</th>\n",
              "      <th>filename</th>\n",
              "      <th>year</th>\n",
              "      <th>index</th>\n",
              "      <th>score</th>\n",
              "      <th>sentence1</th>\n",
              "      <th>sentence2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>main-captions</td>\n",
              "      <td>MSRvid</td>\n",
              "      <td>2012test</td>\n",
              "      <td>1</td>\n",
              "      <td>5.0</td>\n",
              "      <td>A plane is taking off.</td>\n",
              "      <td>An air plane is taking off.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>main-captions</td>\n",
              "      <td>MSRvid</td>\n",
              "      <td>2012test</td>\n",
              "      <td>4</td>\n",
              "      <td>3.8</td>\n",
              "      <td>A man is playing a large flute.</td>\n",
              "      <td>A man is playing a flute.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>main-captions</td>\n",
              "      <td>MSRvid</td>\n",
              "      <td>2012test</td>\n",
              "      <td>5</td>\n",
              "      <td>3.8</td>\n",
              "      <td>A man is spreading shreded cheese on a pizza.</td>\n",
              "      <td>A man is spreading shredded cheese on an uncoo...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-651c3d61-5295-407a-91e4-36cf1e0b3ab3')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-651c3d61-5295-407a-91e4-36cf1e0b3ab3 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-651c3d61-5295-407a-91e4-36cf1e0b3ab3');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "           genre filename      year  index  score  \\\n",
              "0  main-captions   MSRvid  2012test      1    5.0   \n",
              "1  main-captions   MSRvid  2012test      4    3.8   \n",
              "2  main-captions   MSRvid  2012test      5    3.8   \n",
              "\n",
              "                                       sentence1  \\\n",
              "0                         A plane is taking off.   \n",
              "1                A man is playing a large flute.   \n",
              "2  A man is spreading shreded cheese on a pizza.   \n",
              "\n",
              "                                           sentence2  \n",
              "0                        An air plane is taking off.  \n",
              "1                          A man is playing a flute.  \n",
              "2  A man is spreading shredded cheese on an uncoo...  "
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def on_bad_line(values):\n",
        "    return values[:7]\n",
        "\n",
        "columns_mapping = {\n",
        "    0: 'genre',\n",
        "    1: 'filename',\n",
        "    2: 'year',\n",
        "    3: 'index',\n",
        "    4: 'score',\n",
        "    5: 'sentence1',\n",
        "    6: 'sentence2'\n",
        "}\n",
        "\n",
        "# quotings 3 = csv.QUOTE_NONE\n",
        "df = pd.read_csv('sts-train.csv', sep=\"\\t\", on_bad_lines=on_bad_line, engine='python', header=None, encoding='utf-8', quoting=3).rename(columns=columns_mapping)\n",
        "print(f'shape of the Dataframe {df.shape}')\n",
        "df.head(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zeVnUT9qpIs4",
        "outputId": "52e455f2-0525-4955-b663-7c652401eb82"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import nltk\n",
        "nltk.download(\"punkt\")\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from string import punctuation\n",
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "GQHQ4WFLostv"
      },
      "outputs": [],
      "source": [
        "sentences1 = df[\"sentence1\"]\n",
        "sentences2 = df[\"sentence2\"]\n",
        "raw_corpus = np.concatenate((sentences1, sentences2))\n",
        "\n",
        "stop_words = stopwords.words('english')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "3hCmEwJbowXd"
      },
      "outputs": [],
      "source": [
        "def preprocess(sentence):\n",
        "    result = re.sub(f'[{punctuation}]','',sentence).lower()\n",
        "    result = re.sub('\\W', ' ', result).split()\n",
        "    return [w for w in result if w not in stop_words]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yMtBBtL7puED",
        "outputId": "fca43dd7-ba1f-452e-c89f-47bc802954ab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sentence embeddings:\n",
            "tensor([[-0.0181, -0.0986, -0.0317,  ...,  0.0554,  0.0609, -0.0057],\n",
            "        [ 0.0057, -0.0019,  0.0170,  ...,  0.0595,  0.0832,  0.0189],\n",
            "        [ 0.0140,  0.0213, -0.0523,  ...,  0.0343,  0.0553, -0.0274],\n",
            "        ...,\n",
            "        [ 0.0520, -0.0173,  0.0426,  ...,  0.0072,  0.0264, -0.0105],\n",
            "        [ 0.0170, -0.0710, -0.0445,  ..., -0.0774, -0.0491, -0.0099],\n",
            "        [-0.0658,  0.0452,  0.0083,  ..., -0.0447,  0.0587,  0.0640]])\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoTokenizer, AutoModel\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "#Mean Pooling - Take attention mask into account for correct averaging\n",
        "def mean_pooling(model_output, attention_mask):\n",
        "    token_embeddings = model_output[0] #First element of model_output contains all token embeddings\n",
        "    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
        "    return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
        "\n",
        "\n",
        "# Sentences we want sentence embeddings for\n",
        "sentences = ['This is an example sentence', 'Each sentence is converted']\n",
        "\n",
        "# Load model from HuggingFace Hub\n",
        "tokenizer = AutoTokenizer.from_pretrained('sentence-transformers/all-MiniLM-L6-v2')\n",
        "model = AutoModel.from_pretrained('sentence-transformers/all-MiniLM-L6-v2')\n",
        "unique_corpus = list(set(raw_corpus[:5000]))\n",
        "# Tokenize sentences\n",
        "encoded_input = tokenizer(unique_corpus, padding=True, truncation=True, return_tensors='pt')\n",
        "\n",
        "# Compute token embeddings\n",
        "with torch.no_grad():\n",
        "    model_output = model(**encoded_input)\n",
        "\n",
        "# Perform pooling\n",
        "sentence_embeddings = mean_pooling(model_output, encoded_input['attention_mask'])\n",
        "\n",
        "# Normalize embeddings\n",
        "sentence_embeddings = F.normalize(sentence_embeddings, p=2, dim=1)\n",
        "\n",
        "print(\"Sentence embeddings:\")\n",
        "print(sentence_embeddings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "WaRqJs2eqlME"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.preprocessing import minmax_scale\n",
        "similarity_matrix = cosine_similarity(sentence_embeddings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hwBfZXeSuIlU",
        "outputId": "cef967f0-f7b8-4627-a30e-70334f5231a3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sentence: Doctors say one or both boys may die, and that some brain damage is possible if they survive.\n",
            "Top-30 most similar pairs:\n",
            "Doctors say one or both boys may die, and that some brain damage is possible if they survive. \t 1.0000\n",
            "That would make you partially responsible for their death. \t 0.4026\n",
            "2 dead, 2 injured in Nevada middle school shooting \t 0.3806\n",
            "After 26 hours of surgery and a year of anticipation, the boys were separated Sunday at Children's Medical Center of Dallas. \t 0.3802\n",
            "One dead in Ohio school shooting \t 0.3706\n",
            "Teenager and father killed in crash \t 0.3618\n",
            "Two boys are driving. \t 0.3580\n",
            "13 children die in fire Myanmar mosque fire \t 0.3508\n",
            "7 killed, 3 injured in south China road accident \t 0.3495\n",
            "Two boys, one wearing a hat, in a playground. \t 0.3367\n",
            "Sentence: alstom is in competition with japanese and german countries for the contract. \n",
            "Top-30 most similar pairs:\n",
            "alstom is in competition with japanese and german countries for the contract.  \t 1.0000\n",
            "french energy and transport company alstom may sign a contract to build a high-speed rail link between beijing and shanghai.  \t 0.4700\n",
            "Customers include Mitsubishi, Siemens, DBTel, Dell, HP, Palm, Philips, Sharp, and Sony. \t 0.3504\n",
            "Ryanair in new bid for Aer Lingus \t 0.3443\n",
            "brazil's strategic affairs minister roberto mangabeira unger stated brazil's new national defense plan calls for establishing partnerships with countries including russia and france to build a state-of-the-art weapons industry.  \t 0.3330\n",
            "\"It's very difficult to do large syndicated loans in Japan,\" where there is a lack of expertise, says one banker. \t 0.3252\n",
            "American Airlines and Pilots Agree on a New Contract \t 0.3165\n",
            "Pratt &Whitney had said that 75 per cent of the engine equipment would be outsourced to Europe, with final assembly in Germany. \t 0.3085\n",
            "the deal has been in process for several years.  \t 0.3065\n",
            "the legislation is the most recent effort by japan to ascribe more freedom to its tightly controlled military and would overturn a ban on the military use of space.  \t 0.3060\n",
            "Sentence: A blue bird perches on the gloved hand of a person.\n",
            "Top-30 most similar pairs:\n",
            "A blue bird perches on the gloved hand of a person. \t 1.0000\n",
            "A blue bird perched on a gloved hand. \t 0.8864\n",
            "a bird lands in the water. \t 0.5595\n",
            "A black and white bird on a body of water with grass in the background. \t 0.5582\n",
            "A small bird eating from the feeder. \t 0.5424\n",
            "A bird is flapping its wings in the water. \t 0.5339\n",
            "A bird holding on to a metal gate. \t 0.5275\n",
            "A yellow and black bird eats from a bird feeder. \t 0.5232\n",
            "Two birds flying towards water feeder. \t 0.5175\n",
            "A large bird standing on a table picks up a plastic glass containing liquid and places it in a bowl of something. \t 0.5155\n"
          ]
        }
      ],
      "source": [
        "def most_similar(sentence_index):\n",
        "    all_sentence_combinations = []\n",
        "    for j in range(0, len(similarity_matrix)):\n",
        "            all_sentence_combinations.append([similarity_matrix[sentence_index][j], sentence_index, j])\n",
        "    all_sentence_combinations = sorted(all_sentence_combinations, key=lambda x: x[0], reverse=True)\n",
        "    print(\"Sentence: \" + unique_corpus[sentence_index])\n",
        "    print(\"Top-30 most similar pairs:\")\n",
        "    for score, sentence_index, j in all_sentence_combinations[:10]:\n",
        "        print(\"{} \\t {:.4f}\".format(unique_corpus[j], similarity_matrix[sentence_index][j]))\n",
        "\n",
        "most_similar(2)\n",
        "most_similar(21)\n",
        "most_similar(4000)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
